{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.Session(default_bucket='quant-sagemaker-test-roles')\n",
    "bucket = session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = \"eu-central-1\"\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name=region)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {bucket}\")\n",
    "print(f\"sagemaker session region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_path = f\"s3://quant-sagemaker-test-roles/imdb/data/small/train.csv\"\n",
    "test_input_path = f\"s3://quant-sagemaker-test-roles/imdb/data/small/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters = {'epochs': 1,\n",
    "                   'per_device_train_batch_size': 32,\n",
    "                   'model_name': 'distilbert-base-uncased'\n",
    "                   }\n",
    "\n",
    "# create the Estimator\n",
    "estimator = HuggingFace(\n",
    "    entry_point='train.py',\n",
    "    source_dir='./source',\n",
    "    instance_type='ml.g4dn.xlarge',  # Note: needs to be an instance with gpu\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    transformers_version='4.5',\n",
    "    tensorflow_version='2.4',\n",
    "    py_version='py37',\n",
    "    hyperparameters=hyperparameters,\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "estimator.fit({'train': train_input_path, 'test': test_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_data = estimator.model_data\n",
    "model_data = 's3://quant-sagemaker-test-roles/huggingface-tensorflow-training-2021-08-06-08-52-15-250/output/model.tar.gz'\n",
    "print(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "model = HuggingFaceModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    transformers_version='4.6',\n",
    "    tensorflow_version='2.4',\n",
    "    py_version='py37',\n",
    "    source_dir=\"source\",\n",
    "    entry_point=\"inference.py\",\n",
    "    sagemaker_session=session,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = pytorch_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.t2.medium\",\n",
    "    serializer=sagemaker.serializers.JSONSerializer(),\n",
    "    deserializer=sagemaker.deserializers.StringDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = \"this is a very good movie\"\n",
    "predictor.predict(input_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_2 = ['this movie sucks', 'this movie is ok']\n",
    "predictor.predict(input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_3 = ['such a terrible movie', 'what a great movie', 'omg best movie ever']\n",
    "predictor.predict(input_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a 200-line csv file needs \"ml.m5.2xlarge\"? Crazy\n",
    "transformer = model.transformer(instance_count=1, instance_type=\"ml.m5.large\", accept='text/csv',\n",
    "                                        strategy='SingleRecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.transform(test_input_path, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $transformer.output_path ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv(\"test.csv.out\", header=None)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker = boto3.client('sagemaker')\n",
    "job_name = 'pytorch-inference-2021-06-01-19-51-46-244'\n",
    "prefix = 'imdb/batch/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% % time\n",
    "\n",
    "from time import gmtime, strftime\n",
    "\n",
    "batch_job_name = \"Batch-Transform-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "input_location = test_input_path\n",
    "output_location = \"s3://{}/{}/output/{}\".format(bucket, prefix, batch_job_name)\n",
    "\n",
    "request = {\n",
    "    \"TransformJobName\": batch_job_name,\n",
    "    \"ModelName\": job_name,\n",
    "    \"BatchStrategy\": \"SingleRecord\",\n",
    "    \"TransformOutput\": {\n",
    "        \"S3OutputPath\": output_location,\n",
    "        \"Accept\": \"text/csv\",\n",
    "        \"AssembleWith\": \"Line\",\n",
    "    },\n",
    "    \"TransformInput\": {\n",
    "        \"DataSource\": {\"S3DataSource\": {\"S3DataType\": \"S3Prefix\", \"S3Uri\": input_location}},\n",
    "        \"ContentType\": \"text/csv\",\n",
    "        \"SplitType\": \"Line\",\n",
    "        \"CompressionType\": \"None\",\n",
    "    },\n",
    "    \"TransformResources\": {\"InstanceType\": \"ml.m5.large\", \"InstanceCount\": 1},\n",
    "}\n",
    "\n",
    "sagemaker.create_transform_job(**request)\n",
    "print(\"Created Transform job with name: \", batch_job_name)\n",
    "\n",
    "# Wait until the job finishes\n",
    "try:\n",
    "    sagemaker.get_waiter(\"transform_job_completed_or_stopped\").wait(TransformJobName=batch_job_name)\n",
    "finally:\n",
    "    response = sagemaker.describe_transform_job(TransformJobName=batch_job_name)\n",
    "    status = response[\"TransformJobStatus\"]\n",
    "    print(\"Transform job ended with status: \" + status)\n",
    "    if status == \"Failed\":\n",
    "        message = response[\"FailureReason\"]\n",
    "        print(\"Transform failed with the following error: {}\".format(message))\n",
    "        raise Exception(\"Transform job failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $output_location./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% % sh -s $model_data\n",
    "rm - rf model\n",
    "mkdir model\n",
    "aws s3 cp $1 model /\n",
    "tar xvzf model/model.tar.gz - -directory ./model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"sagemaker>=2.31.0\" \"transformers==4.4.2\" \"datasets[s3]==1.5.0\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch_model.bin stores fine-tuned huggingface\n",
    "# tokenizer_config.json stores tokenizer used for training\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('model')\n",
    "tokenizer = AutoTokenizer.from_pretrained('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['this is a terrific movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = tokenizer(inputs, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.Tensor(tokenized_input['input_ids']).long()\n",
    "attention_mask = torch.Tensor(tokenized_input['attention_mask']).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(input_ids, attention_mask).logits\n",
    "    res = np.argmax(logits)\n",
    "    print('logits:', logits, 'neg/pos:', res)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

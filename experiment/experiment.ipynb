{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = \"eu-central-1\"\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name=region)\n",
    "raw_input_path = f\"s3://{bucket}/imdb/processing/raw/small/raw.csv\"\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {bucket}\")\n",
    "print(f\"sagemaker session region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BYO Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "ecr_repository = \"sagemaker-pytorch-processing-container\"\n",
    "tag = \":latest\"\n",
    "\n",
    "uri_suffix = \"amazonaws.com\"\n",
    "processing_repository_uri = f\"{account_id}.dkr.ecr.{region}.{uri_suffix}/{ecr_repository + tag}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Set up the Experiment\n",
    "\n",
    "Create an experiment to track all the model training iterations. Experiments are a great way to organize your data science work. You can create experiments to organize all your model development work for : [1] a business use case you are addressing (e.g. create experiment named “customer churn prediction”), or [2] a data science team that owns the experiment (e.g. create experiment named “marketing analytics experiment”), or [3] a specific data science and ML project. Think of it as a “folder” for organizing your “files”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_experiment = Experiment.create(\n",
    "    experiment_name=f\"Imdb-Experiment\",\n",
    "    description=\"Testing thing out with IMDB experiment\",\n",
    "    sagemaker_boto_client=sm,\n",
    ")\n",
    "print(imdb_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Track Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "script_processor = ScriptProcessor(\n",
    "    command=[\"python3\"],\n",
    "    image_uri=processing_repository_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.t3.medium\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the same `preprocessing.py` script you ran above, but now, this code is running inside of the Docker container you built in this notebook, not the scikit-learn image maintained by Amazon SageMaker. You can add the dependencies to the Docker image, and run your own pre-processing, feature-engineering, and model evaluation scripts inside of this container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_processor.run(\n",
    "    code=\"source/preprocessing.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(source=raw_input_path, destination=\"/opt/ml/processing/input\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    arguments=[\n",
    "        \"--train-test-split-ratio\",\n",
    "        \"0.2\",\n",
    "        \"--model_name\",\n",
    "        \"distilbert-base-uncased\",\n",
    "    ],\n",
    "    experiment_config={\n",
    "        \"TrialComponentDisplayName\": \"Preprocessing\",\n",
    "    },\n",
    ")\n",
    "script_processor_job_description = script_processor.jobs[-1].describe()\n",
    "output_config = script_processor_job_description[\"ProcessingOutputConfig\"]\n",
    "for output in output_config[\"Outputs\"]:\n",
    "    if output[\"OutputName\"] == \"train\":\n",
    "        preprocessed_training_data = output[\"S3Output\"][\"S3Uri\"]\n",
    "    if output[\"OutputName\"] == \"test\":\n",
    "        preprocessed_test_data = output[\"S3Output\"][\"S3Uri\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing_job_name = script_processor_job_description['ProcessingJobName']\n",
    "processing_job_name = 'sagemaker-pytorch-processing-container-2021-07-08-10-29-36-746'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = Tracker.load(processing_job_name=processing_job_name)\n",
    "preprocessing_trial_component = tracker.trial_component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# create trial\n",
    "tf_trial_name = \"imdb-experiment-tf-trial\"\n",
    "# tf_trial = Trial.create(\n",
    "#     trial_name=tf_trial_name,\n",
    "#     experiment_name=imdb_experiment.experiment_name,\n",
    "#     sagemaker_boto_client=sm,\n",
    "# )\n",
    "\n",
    "# associate the proprocessing trial component with the current trial\n",
    "tf_trial.add_trial_component(preprocessing_trial_component)\n",
    "\n",
    "model_path_tf = f\"s3://{bucket}/imdb/model_train/tf\"\n",
    "\n",
    "hyperparameters = {\n",
    "    \"epochs\": 1,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"model_name\": \"distilbert-base-uncased\"\n",
    ",\n",
    "}\n",
    "\n",
    "metric_definitions=[\n",
    "    {'Name': 'traning:loss', 'Regex': \"'loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'validation:loss', 'Regex': \"'eval_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'validation:accuracy', 'Regex': \"'eval_accuracy': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'validation:f1', 'Regex': \"'eval_f1': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'validation:precision', 'Regex': \"'eval_precision': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'validation:recall', 'Regex': \"'eval_recall': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'validation:runtime', 'Regex': \"'eval_runtime': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'validation:samples_per_second', 'Regex': \"'eval_samples_per_second': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'learning_rate', 'Regex': \"'learning_rate': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'epoch', 'Regex': \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"}]\n",
    "\n",
    "# create the Estimator\n",
    "estimator_tf = PyTorch(\n",
    "    entry_point=\"train_tf.py\",\n",
    "    source_dir=\"source\",\n",
    "    instance_type='ml.g4dn.xlarge',\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    framework_version=\"1.6\",\n",
    "    py_version=\"py36\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=model_path_tf,\n",
    "    metric_definitions=metric_definitions,\n",
    ")\n",
    "\n",
    "estimator_tf.fit(\n",
    "    inputs={'train': preprocessed_training_data, 'test': preprocessed_test_data},\n",
    "    experiment_config={\n",
    "        \"TrialName\": tf_trial.trial_name,\n",
    "        \"TrialComponentDisplayName\": \"Training\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "script_processor.run(\n",
    "    code=\"source/evaluation_tf.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(source=estimator_tf.model_data, destination=\"/opt/ml/processing/model\"),\n",
    "        ProcessingInput(source=preprocessed_test_data, destination=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    outputs=[ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\")],\n",
    "    experiment_config={\n",
    "        \"TrialName\": tf_trial.trial_name,\n",
    "        \"TrialComponentDisplayName\": \"Evaluating\",\n",
    "    },\n",
    ")\n",
    "evaluation_job_description = script_processor.jobs[-1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# create trial\n",
    "svm_trial_name = \"imdb-experiment-svm-trial\"\n",
    "# svm_trial = Trial.create(\n",
    "#     trial_name=svm_trial_name,\n",
    "#     experiment_name=imdb_experiment.experiment_name,\n",
    "#     sagemaker_boto_client=sm,\n",
    "# )\n",
    "\n",
    "# associate the proprocessing trial component with the current trial\n",
    "svm_trial.add_trial_component(preprocessing_trial_component)\n",
    "\n",
    "model_path_svm = f\"s3://{bucket}/imdb/model_train/svm\"\n",
    "\n",
    "hyperparameters = {\n",
    "    \"epochs\": 1,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"model_name\": \"distilbert-base-uncased\"\n",
    ",\n",
    "}\n",
    "\n",
    "estimator_svm = PyTorch(\n",
    "    entry_point=\"train_svm.py\",\n",
    "    source_dir=\"source\",\n",
    "    role=role,\n",
    "    framework_version=\"1.6\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type='ml.c4.xlarge',\n",
    "    instance_count=1,\n",
    "    output_path=model_path_svm,\n",
    ")\n",
    "\n",
    "estimator_svm.fit(\n",
    "    inputs={'train': preprocessed_training_data, 'test': preprocessed_test_data},\n",
    "    experiment_config={\n",
    "        \"TrialName\": svm_trial.trial_name,\n",
    "        \"TrialComponentDisplayName\": \"Training\",\n",
    "    },\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker.local import LocalSession\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "train_input_path = f\"s3://{bucket}/imdb/data/small/train.csv\"\n",
    "test_input_path = f\"s3://{bucket}/imdb/data/small/test.csv\"\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={'epochs': 1,\n",
    "                 'per_device_train_batch_size': 32,\n",
    "                 'model_name': 'distilbert-base-uncased'\n",
    "                 }\n",
    "\n",
    "# create the Estimator\n",
    "estimator = HuggingFace(\n",
    "        entry_point='train.py',\n",
    "        source_dir='./source',\n",
    "        instance_type='ml.g4dn.xlarge',  # Note: needs to be an instance with gpu\n",
    "        instance_count=1,\n",
    "        role=role,\n",
    "        transformers_version='4.4',\n",
    "        pytorch_version='1.6',\n",
    "        py_version='py36',\n",
    "        hyperparameters = hyperparameters\n",
    ")\n",
    "estimator.fit({'train': train_input_path, 'test': test_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_data = estimator.model_data\n",
    "model_data = 's3://sagemaker-eu-central-1-611215368770/huggingface-pytorch-training-2021-06-01-18-10-34-763/output/model.tar.gz'\n",
    "print(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=\"s3://sagemaker-eu-central-1-611215368770/pytorch-training-2021-06-01-09-20-56-523/model.tar.gz\",\n",
    "    role=role,\n",
    "    framework_version=\"1.7.1\",\n",
    "    source_dir=\"source\",\n",
    "    py_version=\"py3\",\n",
    "    entry_point=\"inference.py\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = pytorch_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.t2.medium\",\n",
    "    serializer=sagemaker.serializers.JSONSerializer(),\n",
    "    deserializer=sagemaker.deserializers.StringDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = \"this is a very good movie\"\n",
    "predictor.predict(input_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_2 = ['this movie sucks', 'this movie is ok']\n",
    "predictor.predict(input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_3 = ['such a terrible movie', 'what a great movie', 'omg best movie ever']\n",
    "predictor.predict(input_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a 200-line csv file needs \"ml.m5.2xlarge\"? Crazy\n",
    "transformer = pytorch_model.transformer(instance_count=1, instance_type=\"ml.m5.large\", accept='text/csv', strategy ='SingleRecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.transform(test_input_path, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $transformer.output_path ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv(\"test.csv.out\", header=None)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh -s $model_data\n",
    "rm -rf model\n",
    "mkdir model\n",
    "aws s3 cp $1 model/ \n",
    "tar xvzf model/model.tar.gz --directory ./model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"sagemaker>=2.31.0\" \"transformers==4.4.2\" \"datasets[s3]==1.5.0\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch_model.bin stores fine-tuned huggingface\n",
    "# tokenizer_config.json stores tokenizer used for training\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('model')\n",
    "tokenizer = AutoTokenizer.from_pretrained('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['this is a terrific movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = tokenizer(inputs, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.Tensor(tokenized_input['input_ids']).long()\n",
    "attention_mask = torch.Tensor(tokenized_input['attention_mask']).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(input_ids, attention_mask).logits\n",
    "    res = np.argmax(logits)\n",
    "    print('logits:', logits, 'neg/pos:', res)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/pytorch-1.6-cpu-py36-ubuntu16.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
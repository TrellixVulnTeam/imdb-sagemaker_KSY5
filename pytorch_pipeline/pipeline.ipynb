{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker.local import LocalSession\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = \"eu-central-1\"\n",
    "model_package_group_name = f\"ImdbPackageGroupName\"\n",
    "raw_input_uri = f\"s3://{bucket}/imdb/processing/raw/small/raw.csv\"\n",
    "batch_input_uri = f\"s3://{bucket}/imdb/batch/input/small/test.csv\"\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {bucket}\")\n",
    "print(f\"sagemaker session region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce638290-c112-40b9-87a0-3468546274af",
   "metadata": {},
   "source": [
    "## BYO Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92892285-b6b1-4f5a-9dc6-2ad0598220b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "ecr_repository = \"sagemaker-pytorch-processing-container\"\n",
    "tag = \":latest\"\n",
    "\n",
    "uri_suffix = \"amazonaws.com\"\n",
    "processing_repository_uri = f\"{account_id}.dkr.ecr.{region}.{ecr_repository}/{tag}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3162d7a6-e5c5-4863-b82e-172b518f081c",
   "metadata": {},
   "source": [
    "### Define Parameters to Parametrize Pipeline Execution\n",
    "\n",
    "Define Pipeline parameters that you can use to parametrize the pipeline. Parameters enable custom pipeline executions and schedules without having to modify the Pipeline definition.\n",
    "\n",
    "The supported parameter types include:\n",
    "\n",
    "* `ParameterString` - represents a `str` Python type\n",
    "* `ParameterInteger` - represents an `int` Python type\n",
    "* `ParameterFloat` - represents a `float` Python type\n",
    "\n",
    "These parameters support providing a default value, which can be overridden on pipeline execution. The default value specified should be an instance of the type of the parameter.\n",
    "\n",
    "The parameters defined in this workflow include:\n",
    "\n",
    "* `processing_instance_type` - The `ml.*` instance type of the processing job.\n",
    "* `processing_instance_count` - The instance count of the processing job.\n",
    "* `training_instance_type` - The `ml.*` instance type of the training job.\n",
    "* `model_approval_status` - What approval status to register the trained model with for CI/CD purposes ( \"PendingManualApproval\" is the default).\n",
    "* `input_data` - The S3 bucket URI location of the input data\n",
    "* `batch_data` - The S3 bucket URI location of the batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d72fcb-e051-4ff9-af79-98f9125e3aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\", default_value=1\n",
    ")\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=\"ml.t3.medium\"\n",
    ")\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\", default_value=\"ml.g4dn.xlarge\"\n",
    ")\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\"\n",
    ")\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=raw_input_uri,\n",
    ")\n",
    "batch_data = ParameterString(\n",
    "    name=\"BatchData\",\n",
    "    default_value=batch_input_uri,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e4b7cd-53b0-4325-a0fc-9f7d8b18dc9d",
   "metadata": {},
   "source": [
    "### Define a Processing Step for Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5963f8e-a47d-4a8b-8686-dcb88bc84603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "script_processor = ScriptProcessor(\n",
    "    command=[\"python3\"],\n",
    "    image_uri=processing_repository_uri,\n",
    "    role=role,\n",
    "    instance_count=processing_instance_count,\n",
    "    instance_type=processing_instance_type,\n",
    "    base_job_name=\"imdb-preprocess\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7724db-3e1d-42ff-98e0-adea7a0ced48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"ImdbProcess\",\n",
    "    processor=script_processor,\n",
    "    inputs=[ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\")],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=\"source/preprocessing.py\",\n",
    "    job_arguments=[\"--train-test-split-ratio\", \"0.2\", \"--model_name\", \"distilbert-base-uncased\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bfb00c-43f3-4810-86bc-db4f488b7baa",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addd0a59-1779-46dc-852e-1bb56590724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "model_path = f\"s3://{bucket}/imdb/model_train\"\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters = {'epochs': 1,\n",
    "                   'per_device_train_batch_size': 32,\n",
    "                   'model_name': 'distilbert-base-uncased'\n",
    "                   }\n",
    "\n",
    "# create the Estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point='train.py',\n",
    "    source_dir='source',\n",
    "    instance_type=training_instance_type,  \n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    framework_version=\"1.7.1\",\n",
    "    py_version=\"py3\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=model_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f9d393-8aa5-414d-9c52-d4f36712f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"ImdbTrain\",\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"test\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f31684-e8aa-4de9-ab2d-b635760fd4d8",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edf1228-4819-47b7-af03-a20f23a29038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"ImdbEval\",\n",
    "    processor=script_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"source/evaluation.py\",\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fffe6eb-2a64-4c09-80a7-f07c4896c7de",
   "metadata": {},
   "source": [
    "### Define a Create Model Step to Create a Model\n",
    "\n",
    "In order to perform batch transformation using the example model, create a SageMaker model. \n",
    "\n",
    "Specifically, pass in the `S3ModelArtifacts` from the `TrainingStep`, `step_train` properties. The `TrainingStep` `properties` attribute matches the object model of the [DescribeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html) response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebda73a-41b9-418d-8e80-e92dfa5924d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    role=role,\n",
    "    framework_version=\"1.7.1\",\n",
    "    source_dir=\"source\",\n",
    "    py_version=\"py3\",\n",
    "    entry_point=\"inference.py\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751c0d1-8972-4308-9041-48da4ddbdb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = pytorch_model.serving_image_uri(region_name=region, instance_type=training_instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4397cb34-b306-4e9e-8ed1-e236a89f8fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=session,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a7af66-54bb-4c55-8e8e-fbe02c88e59b",
   "metadata": {},
   "source": [
    "Supply the model input -- `instance_type` and `accelerator_type` for creating the SageMaker Model and then define the `CreateModelStep` passing in the inputs and the model instance defined before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9921f869-f89d-43a8-9cac-7cbcd14c711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "\n",
    "\n",
    "inputs = CreateModelInput(\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "#     accelerator_type=\"ml.eia1.medium\",\n",
    ")\n",
    "step_create_model = CreateModelStep(\n",
    "    name=\"ImdbModel\",\n",
    "    model=model,\n",
    "#     model=pytorch_model,\n",
    "    inputs=inputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b7429a-b613-4a54-9e8c-d4ee3aa1bb18",
   "metadata": {},
   "source": [
    "### Define a Transform Step to Perform Batch Transformation\n",
    "\n",
    "Now that a model instance is defined, create a `Transformer` instance with the appropriate model type, compute instance type, and desired output S3 URI.\n",
    "\n",
    "Specifically, pass in the `ModelName` from the `CreateModelStep`, `step_create_model` properties. The `CreateModelStep` `properties` attribute matches the object model of the [DescribeModel](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeModel.html) response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc2cd9b-23dd-4bf1-9483-d8b2edaa71fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    output_path=f\"s3://{bucket}/imdb/transform\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41acd20-2825-409d-bd55-c5deace3d64e",
   "metadata": {},
   "source": [
    "Pass in the transformer instance and the `TransformInput` with the `batch_data` pipeline parameter defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d49c56-e581-4df8-bd53-c2c4a8914701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name=\"ImdbTransform\", transformer=transformer, inputs=TransformInput(data=batch_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b887c67a-0c99-481b-b0c2-991108f21b1a",
   "metadata": {},
   "source": [
    "### Define a Register Model Step to Create a Model Package\n",
    "\n",
    "Use the estimator instance specified in the training step to construct an instance of `RegisterModel`. The result of executing `RegisterModel` in a pipeline is a model package. A model package is a reusable model artifacts abstraction that packages all ingredients required for inference. Primarily, it consists of an inference specification that defines the inference image to use along with an optional model weights location.\n",
    "\n",
    "A model package group is a collection of model packages. A model package group can be created for a specific ML business problem, and new versions of the model packages can be added to it. Typically, customers are expected to create a ModelPackageGroup for a SageMaker pipeline so that model package versions can be added to the group for every SageMaker Pipeline run.\n",
    "\n",
    "The construction of `RegisterModel` is similar to an estimator instance's `register` method in the Python SDK.\n",
    "\n",
    "Specifically, pass in the `S3ModelArtifacts` from the `TrainingStep`, `step_train` properties. The `TrainingStep` `properties` attribute matches the object model of the [DescribeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html) response object.\n",
    "\n",
    "Note that the specific model package group name provided in this notebook can be used in the model registry and CI/CD work with SageMaker Projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1090e41a-5895-431c-a106-d04cef520742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=f\"\"\"{step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]}/evaluation.json\"\"\",\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "step_register = RegisterModel(\n",
    "    name=\"ImdbRegisterModel\",\n",
    "    estimator=estimator,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c4a8ca-c538-4dab-8356-c9a2ea02d7a1",
   "metadata": {},
   "source": [
    "### Define a Pipeline of Parameters, Steps, and Conditions\n",
    "\n",
    "In this section, combine the steps into a Pipeline so it can be executed.\n",
    "\n",
    "A pipeline requires a `name`, `parameters`, and `steps`. Names must be unique within an `(account, region)` pair.\n",
    "\n",
    "Note:\n",
    "\n",
    "* All of the parameters used in the definitions must be present.\n",
    "* Steps passed into the pipeline do not have to be listed in the order of execution. The SageMaker Pipeline service resolves the _data dependency_ DAG as steps for the execution to complete.\n",
    "* Steps must be unique to across the pipeline step list and all condition step if/else lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c4f93b-12f0-41a8-a627-8a1b1a21bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipeline_name = f\"ImdbPipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        training_instance_type,\n",
    "        model_approval_status,\n",
    "        input_data,\n",
    "        batch_data,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval, step_register, step_create_model, step_transform],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857902d9-2286-48f1-acd3-4109991a6fb7",
   "metadata": {},
   "source": [
    "#### (Optional) Examining the pipeline definition\n",
    "\n",
    "The JSON of the pipeline definition can be examined to confirm the pipeline is well-defined and the parameters and step properties resolve correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d346ab72-975b-49c3-8db1-6279f720d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f82d6f-9093-47a9-afdc-81ea1ac5ae1a",
   "metadata": {},
   "source": [
    "### Submit the pipeline to SageMaker and start execution\n",
    "\n",
    "Submit the pipeline definition to the Pipeline service. The role passed in will be used by the Pipeline service to create all the jobs defined in the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ed203b-ae88-4f50-bd8e-2630918a1da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c33a35-93d9-4fa3-8377-4085c2783d3a",
   "metadata": {},
   "source": [
    "Start the pipeline and accept all of the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba482198-012f-4c33-a6c7-80b043ba6bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406002ca-9d68-43fc-8a83-6d5c0d17fee1",
   "metadata": {},
   "source": [
    "### Pipeline Operations: Examining and Waiting for Pipeline Execution\n",
    "\n",
    "Describe the pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bcbeb9-5e24-4cee-b4a4-2c1ed4903b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295f4331-e4e4-4a81-99de-5af5ac6cb8da",
   "metadata": {},
   "source": [
    "Wait for the execution to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3651ba2-2ffa-41f2-b382-158c1550c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1012e4a-737d-40e6-a67f-513d659ee1f2",
   "metadata": {},
   "source": [
    "List the steps in the execution. These are the steps in the pipeline that have been resolved by the step executor service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f5c6d7-a4c4-4af7-9fd3-abe5cc513035",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
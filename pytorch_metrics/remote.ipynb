{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d609e-004d-4f68-a708-639a6f5a4027",
   "metadata": {},
   "source": [
    "# Launching a Training Job with custom metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffed2436-6980-4e95-aefb-4893d7214e34",
   "metadata": {},
   "source": [
    "We create a metric_definition dictionary that contains regex-based definitions that will be used to parse the job logs and extract metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415fb98f-91bc-43ae-a37d-d0468bcf7282",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions=[\n",
    "    {'Name': 'loss', 'Regex': \"'loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'learning_rate', 'Regex': \"'learning_rate': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_loss', 'Regex': \"'eval_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_accuracy', 'Regex': \"'eval_accuracy': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_f1', 'Regex': \"'eval_f1': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_precision', 'Regex': \"'eval_precision': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_recall', 'Regex': \"'eval_recall': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_runtime', 'Regex': \"'eval_runtime': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_samples_per_second', 'Regex': \"'eval_samples_per_second': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'epoch', 'Regex': \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-latvia",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "train_input_path = f\"s3://{bucket}/imdb/data/small/train.csv\"\n",
    "test_input_path = f\"s3://{bucket}/imdb/data/small/test.csv\"\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-outreach",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters = {'epochs': 1,\n",
    "                   'per_device_train_batch_size': 32,\n",
    "                   'model_name': 'distilbert-base-uncased'\n",
    "                   }\n",
    "\n",
    "# create the Estimator\n",
    "estimator = HuggingFace(\n",
    "    entry_point='train.py',\n",
    "    source_dir='./source',\n",
    "    instance_type='ml.g4dn.xlarge',  # Note: needs to be an instance with gpu\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    transformers_version='4.4',\n",
    "    pytorch_version='1.6',\n",
    "    py_version='py36',\n",
    "    hyperparameters=hyperparameters\n",
    ")\n",
    "estimator.fit({'train': train_input_path, 'test': test_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fe0121-287d-4e2f-b6db-2edc17a4c2d6",
   "metadata": {},
   "source": [
    "## Accessing Training Metrics\n",
    "\n",
    "The training job doesn't emit metrics immediately. For example, it first needs to provision a training instance, download the training image, download the data. Additionally in this demo the first evaluation logs come after 500 steps (default in the Hugging Face trainer https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments).\n",
    "\n",
    "Hence, **run the below section 15 to 20 minutes after launching the training, otherwise it may not have available metrics yet and return an error**\n",
    "\n",
    "Note that you can also copy this code and run it from a different place (as long as connected to the cloud and authorized to use the API), by specifiying the exact training job name in the `TrainingJobAnalytics` API call.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22ea0d5-edeb-4cd2-ad4c-37326efcdc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import TrainingJobAnalytics\n",
    "\n",
    "# Captured metrics can be accessed as a Pandas dataframe\n",
    "df = TrainingJobAnalytics(training_job_name=huggingface_estimator.latest_training_job.name).dataframe()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ccb22b-ae98-448a-9ae3-062b681964f5",
   "metadata": {},
   "source": [
    "We can also plot some of the metrics collected\n",
    "\n",
    "*Note: the plot below were generated at the end of the training job, with metrics available for all training duration*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edbeca6-87b9-40d3-a793-fde3308e245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a4c28f-4dc7-4c47-a853-c4ae6c9cd556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b634839-9db4-4d5d-a8f4-aa8fb7252404",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = df[df.metric_name.isin(['eval_accuracy','eval_precision'])]\n",
    "losses = df[df.metric_name.isin(['loss', 'eval_loss'])]\n",
    "\n",
    "sns.lineplot(\n",
    "    x='timestamp', \n",
    "    y='value', \n",
    "    data=evals, \n",
    "    hue='metric_name', \n",
    "    palette=['blue', 'purple'])\n",
    "\n",
    "ax2 = plt.twinx()\n",
    "sns.lineplot(\n",
    "    x='timestamp', \n",
    "    y='value', \n",
    "    data=losses, \n",
    "    hue='metric_name', \n",
    "    palette=['orange', 'red'],\n",
    "    ax=ax2)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
